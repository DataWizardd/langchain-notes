{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4355356b-a3ae-4fdf-8a67-ab2caf68f29d",
   "metadata": {},
   "source": [
    "# LangChain 시작하기\n",
    "\n",
    "## 01. 랭체인(LangChain) 개요\n",
    "\n",
    "### 📌 개요\n",
    "- **LangChain** = LLM을 실용적으로 사용하기 위한 프레임워크\n",
    "- 목적:\n",
    "  1. **LLM + 외부 데이터** (DB, 문서, API 등) 연결\n",
    "  2. **LLM + 도구** (검색, 계산기, 코드 실행) 연결\n",
    "  3. **LLM 워크플로우** 관리 및 체인화\n",
    "\n",
    "### ⚙️ 주요 구성 요소\n",
    "| 구성 요소 | 설명 |\n",
    "|-----------|------|\n",
    "| **PromptTemplate** | 프롬프트를 템플릿화하여 재사용 가능 |\n",
    "| **LLM** | GPT, Claude, LLaMA 등 다양한 모델 연결 |\n",
    "| **Chains** | 여러 단계를 묶어 순차적으로 실행 |\n",
    "| **Agents** | LLM이 도구(검색, 계산기, DB 등)를 선택·실행 |\n",
    "| **Memory** | 대화 기록 및 컨텍스트 유지 |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 02. LangChain\n",
    "\n",
    "### 📌 개념\n",
    "- LangChain은 **OpenAI, Anthropic, HuggingFace** 등 다양한 LLM 연결 지원\n",
    "- `ChatOpenAI` 클래스로 대화형 모델과 직접 통신\n",
    "- **temperature**: 창의성 조절 (0 = 정확성↑, 1 = 다양성↑)  \n",
    "- **model**: 모델 종류 선택 (예: `gpt-3.5-turbo`, `gpt-4o-mini`)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c042523b-c6f7-4bb4-9621-e24deb304bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-73\n"
     ]
    }
   ],
   "source": [
    "### 💻 예시 코드\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08819775-7b3d-4e37-b599-69421a6ed88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 언어 간 상호작용을 촉진하기 위해 설계된 블록체인 기술입니다. 이 기술은 다양한 언어간 커뮤니케이션을 용이하게 하고, 어휘, 문법, 문화 차이를 극복하는데 도움을 줍니다. LangChain은 전 세계 사람들이 서로 소통하고 협력할 수 있는 환경을 제공하는 것을 목표로 합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 질문 보내기\n",
    "response = llm.invoke(\"LangChain이 무엇인지 간단히 설명해줘\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef825ef-8474-4f92-b9ff-147be162e78a",
   "metadata": {},
   "source": [
    "## 03. 토큰(Token), 토큰계산기, 모델별 비용\n",
    "\n",
    "### 📌 개념\n",
    "\n",
    "- 토큰(Token) = 언어모델이 처리하는 최소 단위 (sub-word, 음절 단위)\n",
    "- 토큰 수 = 입력 + 출력 합산 (→ 비용과 속도에 영향)\n",
    "- Context Window = 모델이 한 번에 처리 가능한 최대 토큰 수\n",
    "- 비용 = 모델별 1K tokens 기준 요금 존재 (예: GPT-3.5 = $0.0015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a5cbc-ea60-4464-b650-c88513a152ae",
   "metadata": {},
   "source": [
    "## 04. ChatOpenAI 주요 파라미터, invoke(), stream() \n",
    "\n",
    "### 📌 주요 파라미터\n",
    "- **model** : 사용할 모델 이름 (예: `gpt-3.5-turbo`, `gpt-4o`)\n",
    "- **temperature** : 창의성 조절 (0 → 사실 위주, 1 → 창의적)\n",
    "- **max_tokens** : 출력 최대 토큰 수\n",
    "- **top_p, top_k** : 샘플링 방식 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5bbe48-13b0-4172-9a71-eb3541d9f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 언어 번역 및 통역을 제공하는 플랫폼으로, 사용자들은 다양한 언어 간의 소통을 쉽게 할 수 있습니다. 또한 블록체인 기술을 활용하여 보안성과 신뢰성을 높이며, 지속적인 언어 학습과 발전을 지원합니다. 또한 사용자들은 LangChain 내에서 다양한 언어 관련 서비스를 이용할 수 있습니다.\n",
      "----------------------------------------------\n",
      "알겠습니다! 무엇을 도와드릴까요?"
     ]
    }
   ],
   "source": [
    "### 💻 예시 코드\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# invoke() → 한번에 응답 생성\n",
    "response = llm.invoke(\"LangChain의 핵심 기능을 3줄로 요약해줘.\")\n",
    "print(response.content)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "# stream() → 스트리밍 응답\n",
    "for chunk in llm.stream(\"실시간으로 답변을 생성해줘.\"):\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5510210b-1a52-4680-b15b-a68b36872456",
   "metadata": {},
   "source": [
    "## 05. LangSmith 로 GPT 추론내용 추적\n",
    "### 📌 개념\n",
    "\n",
    "- LangSmith = LangChain 공식 실험/관찰 플랫폼\n",
    "- LLM 추론 과정(입력, 출력, 체인 실행 로그) 기록 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a1169b-786e-4ad9-8d29-6023a4c25931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, the weather is really nice today.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "prompt = PromptTemplate.from_template(\"다음 문장을 영어로 번역해줘: {sentence}\")\n",
    "\n",
    "# 체인 생성 (LCEL)\n",
    "chain = prompt | llm\n",
    "\n",
    "# 실행 (LangSmith 대시보드에 자동 기록됨)\n",
    "result = chain.invoke({\"sentence\": \"안녕하세요, 오늘 날씨가 참 좋네요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa654b9e-44a1-4b91-ab4c-fbc8bbf52c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go watch a movie tonight.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "parser_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "result = parser_chain.invoke({\"sentence\": \"오늘 저녁에 영화 보러 가자.\"})\n",
    "print(result)  # 문자열만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1400130e-5beb-478f-8414-03040ef1c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english': 'I drank coffee this morning.', 'french': 'Je ai bu du café ce matin.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "multi_chain = RunnableParallel(\n",
    "    english=(PromptTemplate.from_template(\"Translate to English: {text}\") | llm | StrOutputParser()),\n",
    "    french=(PromptTemplate.from_template(\"Translate to French: {text}\") | llm | StrOutputParser())\n",
    ")\n",
    "\n",
    "result = multi_chain.invoke({\"text\": \"나는 오늘 아침에 커피를 마셨다.\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce552c-7be3-424c-84ae-f0cdba9081cb",
   "metadata": {},
   "source": [
    "## 06. GPT-4o (멀티모달) 모델로 이미지 인식하여 답변 출력\n",
    "### 📌 개념\n",
    "\n",
    "- GPT-4o = OpenAI 멀티모달 모델\n",
    "- 텍스트 + 이미지 입력 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7176838-b9d3-4581-8a69-4d7effa6cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지에는 \"MOTEL\"이라는 글자가 쓰인 간판이 보입니다. 간판은 기둥에 세워져 있고 하늘을 배경으로 하고 있습니다. 상단에는 안테나 같은 구조물이 보입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"이 이미지에는 무엇이 보이나요?\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": \"https://picsum.photos/200\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = llm.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e554c-c986-4a97-84ee-2b8f8414dd62",
   "metadata": {},
   "source": [
    "## 07. LCEL 로 Chain 생성 \n",
    "### 📌 개념\n",
    "\n",
    "- LCEL (LangChain Expression Language)\n",
    "- 체인을 직관적으로 | 연산자로 연결 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77bf354-66e1-4058-8940-52fba53e151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋은 아침 (joh-eun achim)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Translate the following into Korean: {text}\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"text\": \"Good morning\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af74d0-04c2-4934-b22e-0501e1bbe7a3",
   "metadata": {},
   "source": [
    "- 여러 입력을 동시에 처리 (batch inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72dfd1f-67b4-48e7-9ba8-2ed3c9e2a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요', '감사합니다 (gam-sa-ham-ni-da)']\n"
     ]
    }
   ],
   "source": [
    "inputs = [{\"text\": \"Hello\"}, {\"text\": \"Thank you\"}]\n",
    "results = chain.batch(inputs)\n",
    "print([r for r in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c347a8-6639-4043-9ba2-a8a3292953be",
   "metadata": {},
   "source": [
    "## 08. 출력파서(StrOutputParser) 를 체인에 연결 \n",
    "### 📌 개념\n",
    "\n",
    "- 모델 출력 → 문자열로 변환\n",
    "- 여러 후처리 파서 제공 (JSON, List 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8df5866-3f66-4fc0-bc49-d040f318c548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반가워요\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "print(chain.invoke({\"text\": \"Nice to meet you\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88850a1-c464-4a8d-af8b-43d5cc4ff29e",
   "metadata": {},
   "source": [
    "## 09. 비동기(asynchronous) 호출 방법 \n",
    "### 📌 개념\n",
    "\n",
    "- asyncio 기반 비동기 실행\n",
    "- 동시에 여러 요청 처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147dd3b3-1a4f-415f-857a-f475f580159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# async def run_async():\n",
    "#     result = await chain.ainvoke({\"text\": \"Good night\"})\n",
    "#     print(result)\n",
    "\n",
    "# asyncio.run(run_async())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6feebd-d720-4c3a-bbe1-aabe49c800c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘 자세요 (jal jaseyo)\n"
     ]
    }
   ],
   "source": [
    "result = await chain.ainvoke({\"text\": \"Good night\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72e7dc-ef26-4ff7-8d58-7c9ed56951b2",
   "metadata": {},
   "source": [
    "## 10. 병렬체인 구성(RunnableParallel)\n",
    "### 📌 개념\n",
    "\n",
    "- 여러 체인을 병렬로 실행 후 결과 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a34c216-6b0e-433a-94d5-4c12cda3c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'korean': '\"How are you?\" in Korean is \"잘 지내세요?\" (jal jinaeseyo?).', 'english': '\"How are you?\" can be translated into Korean as \"어떻게 지내세요?\"'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    korean=prompt | llm | StrOutputParser(),\n",
    "    english=prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "results = parallel_chain.invoke({\"text\": \"How are you?\"})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3ec61-f17a-4ce7-bda8-68b532e2710e",
   "metadata": {},
   "source": [
    "## 11. 값을 전달해주는 RunnablePassthrough\n",
    "### 📌 개념\n",
    "\n",
    "- 입력을 그대로 다음 체인에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84a18f0-a126-42f3-9f57-331e7fe0dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 원하시는 문장을 말씀해주시면 그대로 전달해드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "passthrough_chain = RunnablePassthrough() | llm\n",
    "response = passthrough_chain.invoke(\"그냥 이 문장을 모델로 보내줘.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7010ab-a2e4-4078-b76f-b12337fc617e",
   "metadata": {},
   "source": [
    "## 12. 병렬로 Runnable 을 실행하는 RunnableParallel\n",
    "### 📌 개념\n",
    "\n",
    "- 여러 Runnable을 동시에 실행\n",
    "- 결과를 dict 형태로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f088f3-4fdb-4263-8dae-7a774f17f15a",
   "metadata": {},
   "source": [
    "## 13. 함수를 실행하는 RunnableLambda, itemgetter\n",
    "### 📌 개념\n",
    "\n",
    "- RunnableLambda : Python 함수 실행을 Runnable로 래핑\n",
    "- itemgetter : 입력 dict에서 특정 key만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7380924d-0211-47fc-8a8a-ef27d0113ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_80956533cb', 'id': 'chatcmpl-C9aMg2lxJptqDHcmFXXHAb5Hf1gwK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--df4b1473-ed8e-4b5e-8e3c-b1548cc6b6cc-0' usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "I'm glad to hear that you're enjoying LangChain! It's a popular framework for building applications with large language models. If you have any questions or need more information about how to make the most out of LangChain, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "def to_upper(x):\n",
    "    return x.upper()\n",
    "\n",
    "lambda_chain = RunnableLambda(to_upper) | llm\n",
    "print(lambda_chain.invoke(\"hello\"))\n",
    "\n",
    "# itemgetter 예시\n",
    "getter_chain = itemgetter(\"text\") | llm\n",
    "print(getter_chain.invoke({\"text\": \"LangChain is fun\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e406c-06a4-4c18-b6b6-413d3eae1088",
   "metadata": {},
   "source": [
    "## ✅ 정리\n",
    "\n",
    "- ChatOpenAI 주요 메서드: invoke(), stream(), batch(), ainvoke()\n",
    "\n",
    "- LCEL 문법으로 체인을 직관적으로 구성 가능 (|)\n",
    "\n",
    "- LangSmith에서 체인 실행과정을 모니터링 가능\n",
    "\n",
    "- Runnable 계열 (RunnableParallel, RunnablePassthrough, RunnableLambda)로 유연한 체인 설계 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e60044-cc02-4dac-85d2-ea168a9b0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
