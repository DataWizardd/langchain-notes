{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd8a4fe-4383-4653-b204-97d128e61917",
   "metadata": {},
   "source": [
    "### 📌 01. LLM 에 도구 바인딩\n",
    "- LLM 단독 → 단순 텍스트 생성\n",
    "- **Tools** 바인딩 → 검색, 계산, DB 질의 등 기능 확장\n",
    "- `load_tools()`로 불러와서 Agent에 결합\n",
    "- Agent는 질문을 보고 적절한 Tool을 선택하여 실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52065990-f65a-4502-a74b-4b3c3f1191cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d3a14d-d7f0-4825-9749-ac0538a0bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_3904\\2506427008.py:13: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_3904\\2506427008.py:15: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"서울의 현재 날씨를 검색하고, 256의 제곱근을 계산해줘\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use DuckDuckGo search to find the current weather in Seoul and then use the calculator to calculate the square root of 256.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"current weather in Seoul\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m16시간 전 — Current weather condition is Partly cloudy with real-time temperature (27°C), humidity 89%, wind 6.5km/h, pressure (1013mb), UV (0), visibility (10km) in ... 2일 전 — Get Seoul, 11, KR current weather report with temperature, feels like, wind ... Seoul, 11, KR Current Weather. Seoul, 11, KR. Updated 6 minutes ago. 31. °C. 7시간 전 — TodayHourly14 DaysPastClimate. Currently: 84 °F . Partly sunny. (Weather station: Seoul / Kimp'O International Airport, South Korea). See more current weather. 2025. 8. 4. — This is a weather conditions table that shows the location, weather , temperature , precipitation, wind, air pressure, etc. Time, Weather , Temp.(℃) ... 2025. 8. 17. — Check the weather forecast for Seoul. Current temperature: 25°C . Conditions: Clear sky. Detailed 7-day forecast.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I need to calculate the square root of 256 using the calculator.\n",
      "Action: Calculator\n",
      "Action Input: sqrt(256)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 16.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The current weather in Seoul is partly cloudy with a temperature of 27°C, and the square root of 256 is 16.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in Seoul is partly cloudy with a temperature of 27°C, and the square root of 256 is 16.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install duckduckgo-search\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# DuckDuckGo 툴 직접 로드\n",
    "ddg_search = DuckDuckGoSearchRun()\n",
    "tools = load_tools([\"llm-math\"], llm=llm) + [ddg_search]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "agent.run(\"서울의 현재 날씨를 검색하고, 256의 제곱근을 계산해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be83575-7034-4962-bd7c-4a1b9235a1c1",
   "metadata": {},
   "source": [
    "### 📌 02. Agent, AgentExecutor 생성\n",
    "- `Agent` = 실행 전략(도구 선택 방식)\n",
    "- `AgentExecutor` = Agent + Tool 실행 관리자\n",
    "- `invoke({\"input\": ...})` 로 실행\n",
    "- `initialize_agent` vs `AgentExecutor`\n",
    "  - 전자는 빠른 초기화\n",
    "  - 후자는 세밀한 제어 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696bae70-3814-40be-a81d-307ff8d061ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `sqrt(256)`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 16.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `3^4`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 81\u001b[0m\u001b[32;1m\u001b[1;3m256의 제곱근은 16이고, 3의 4제곱은 81입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '256의 제곱근은 뭐야? 그리고 3^4는?',\n",
       " 'output': '256의 제곱근은 16이고, 3의 4제곱은 81입니다.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent, load_tools\n",
    "\n",
    "# 1) LLM 준비\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 2) 사용할 툴 \n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# 3) 프롬프트: 반드시 agent_scratchpad 자리 포함!\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# 4) 함수형 에이전트 생성\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# 5) 실행기\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 6) 호출\n",
    "executor.invoke({\"input\": \"256의 제곱근은 뭐야? 그리고 3^4는?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7e8ae-1612-4c24-92a5-c1e21468672b",
   "metadata": {},
   "source": [
    "### 📌 03. 중간단계 스트리밍\n",
    "- `streaming=True` 설정 → 토큰 단위 스트리밍 출력\n",
    "- `AgentStreamParser` 활용 → **Tool 선택, Thought, Observation** 단계별 추적 가능\n",
    "- 디버깅/모니터링에 유용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44158e25-68a2-4fd5-9582-fa1e58b3e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `sqrt(3)`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 1.7320508075688772\u001b[0m3의 제곱근은 1.7320508075688772 입니다.\u001b[32;1m\u001b[1;3m3의 제곱근은 1.7320508075688772 입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '3의 제곱근은?', 'output': '3의 제곱근은 1.7320508075688772 입니다.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent 의 중간단계 스트리밍 (AgentStreamParser)\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "streaming_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "agent = create_openai_functions_agent(streaming_llm, tools, prompt)\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "executor.invoke({\"input\": \"3의 제곱근은?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b773e8-5063-468a-bcf8-be5d5bfaab30",
   "metadata": {},
   "source": [
    "### 📌 04. Agent 메모리 추가\n",
    "- 기본 Agent는 상태 없음 → 멀티턴 대화 불가\n",
    "- `ConversationBufferMemory` 추가 → 이전 대화 저장\n",
    "- 다양한 메모리 적용 가능:\n",
    "  - BufferMemory\n",
    "  - SummaryMemory\n",
    "  - TokenBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823c5277-dd95-4065-936c-af2ee38b2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m안녕하세요, DataWizardd님! 무엇을 도와드릴까요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m당연히 DataWizardd님이세요! 어떻게 도와드릴까요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "당연히 DataWizardd님이세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent, load_tools\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 툴은 예시로 llm-math만\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# 프롬프트에 chat_history와 agent_scratchpad 둘 다 반드시 포함!\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),          # ← 메모리 주입 지점\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),      # ← 에이전트 중간 단계 기록\n",
    "])\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# 기존 메모리와 키 이름 맞추기\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "\n",
    "executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "\n",
    "executor.invoke({\"input\": \"내 이름은 DataWizardd야\"})\n",
    "print(executor.invoke({\"input\": \"내 이름이 뭐였지?\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e2604-cae9-406b-85f0-d233b8e46425",
   "metadata": {},
   "source": [
    "### 📌 05. 다양한 LLM 기반 Agent\n",
    "- LangChain은 여러 LLM Provider 지원\n",
    "- **OpenAI, Anthropic(Claude), Google(Gemini), TogetherAI, Ollama** 등\n",
    "- 동일한 Agent 구조에 다른 LLM 바인딩만 교체 → 호환성 높음\n",
    "- 👉 상황/비용/성능 요구에 따라 LLM 교체 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4079144b-4992-4ea4-a26a-fc31b96b0515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 다양하게 교체 가능\n"
     ]
    }
   ],
   "source": [
    "# 다양한 LLM 을 활용한 에이전트 생성\n",
    "\n",
    "# OpenAI GPT\n",
    "gpt_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Anthropic Claude (예시: langchain-anthropic 필요)\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# claude_llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "# Google Gemini (예시: langchain-google-genai 필요)\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# TogetherAI\n",
    "# from langchain_community.chat_models import ChatTogether\n",
    "# together_llm = ChatTogether(model=\"together/gpt-neoxt\")\n",
    "\n",
    "# Ollama (로컬 실행)\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# ollama_llm = ChatOllama(model=\"llama2\")\n",
    "\n",
    "print(\"LLM 다양하게 교체 가능\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192333d5-5fea-459e-9d1f-2fb81b765bff",
   "metadata": {},
   "source": [
    "### 📌 06. iter() & Human-in-the-loop\n",
    "- `executor.iter()` → Agent 실행 과정을 단계별 반환\n",
    "- 각 단계: Thought → Action → Observation\n",
    "- Human-in-the-loop:\n",
    "  - 실행 중간에 사람이介入해 결과 수정/결정 가능\n",
    "  - 보안/품질 요구가 높은 워크플로우에 적합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e5200d-6171-4621-a3b1-5c81bc5c34c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new None chain...\u001b[0m\n",
      "대한민국의 수도는 서울입니다.\u001b[32;1m\u001b[1;3m대한민국의 수도는 서울입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "단계 출력: {'output': '대한민국의 수도는 서울입니다.', 'messages': [AIMessage(content='대한민국의 수도는 서울입니다.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\langchain\\chains\\base.py:487: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'messages']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  self.memory.save_context(inputs, outputs)\n"
     ]
    }
   ],
   "source": [
    "# iter() 함수로 단계별 출력과 Human-in-the-loop\n",
    "\n",
    "for step in executor.iter({\"input\": \"대한민국의 수도는 어디야?\"}):\n",
    "    print(\"단계 출력:\", step)\n",
    "    # 사람이 중간에 intervention 가능 (예: Tool 결과 수정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f30480-60a4-4a6f-8498-424a207b7468",
   "metadata": {},
   "source": [
    "# ✅ 최종 정리\n",
    "- **Binding Tools** → Agent 기능 확장\n",
    "- **Agent & Executor** → 전략 + 실행 관리\n",
    "- **Streaming & Parser** → 단계별 스트리밍 모니터링\n",
    "- **Memory 추가** → 멀티턴 대화 지원\n",
    "- **다양한 LLM 교체** → GPT, Claude, Gemini, Together, Ollama\n",
    "- **iter()** → 단계별 실행 확인 + Human-in-the-loop介入\n",
    "\n",
    "👉 Agent는 LLM을 **도구 활용 가능한 지능적 실행자**로 확장하는 핵심 모듈\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
