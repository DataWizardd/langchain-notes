{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd8a4fe-4383-4653-b204-97d128e61917",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 01. LLM ì— ë„êµ¬ ë°”ì¸ë”©\n",
    "- LLM ë‹¨ë… â†’ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "- **Tools** ë°”ì¸ë”© â†’ ê²€ìƒ‰, ê³„ì‚°, DB ì§ˆì˜ ë“± ê¸°ëŠ¥ í™•ì¥\n",
    "- `load_tools()`ë¡œ ë¶ˆëŸ¬ì™€ì„œ Agentì— ê²°í•©\n",
    "- AgentëŠ” ì§ˆë¬¸ì„ ë³´ê³  ì ì ˆí•œ Toolì„ ì„ íƒí•˜ì—¬ ì‹¤í–‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52065990-f65a-4502-a74b-4b3c3f1191cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d3a14d-d7f0-4825-9749-ac0538a0bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_3904\\2506427008.py:13: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_3904\\2506427008.py:15: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ê²€ìƒ‰í•˜ê³ , 256ì˜ ì œê³±ê·¼ì„ ê³„ì‚°í•´ì¤˜\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use DuckDuckGo search to find the current weather in Seoul and then use the calculator to calculate the square root of 256.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"current weather in Seoul\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m16ì‹œê°„ ì „ â€” Current weather condition is Partly cloudy with real-time temperature (27Â°C), humidity 89%, wind 6.5km/h, pressure (1013mb), UV (0), visibility (10km) in ... 2ì¼ ì „ â€” Get Seoul, 11, KR current weather report with temperature, feels like, wind ... Seoul, 11, KR Current Weather. Seoul, 11, KR. Updated 6 minutes ago. 31. Â°C. 7ì‹œê°„ ì „ â€” TodayHourly14 DaysPastClimate. Currently: 84 Â°F . Partly sunny. (Weather station: Seoul / Kimp'O International Airport, South Korea). See more current weather. 2025. 8. 4. â€” This is a weather conditions table that shows the location, weather , temperature , precipitation, wind, air pressure, etc. Time, Weather , Temp.(â„ƒ) ... 2025. 8. 17. â€” Check the weather forecast for Seoul. Current temperature: 25Â°C . Conditions: Clear sky. Detailed 7-day forecast.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I need to calculate the square root of 256 using the calculator.\n",
      "Action: Calculator\n",
      "Action Input: sqrt(256)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 16.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The current weather in Seoul is partly cloudy with a temperature of 27Â°C, and the square root of 256 is 16.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in Seoul is partly cloudy with a temperature of 27Â°C, and the square root of 256 is 16.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install duckduckgo-search\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# DuckDuckGo íˆ´ ì§ì ‘ ë¡œë“œ\n",
    "ddg_search = DuckDuckGoSearchRun()\n",
    "tools = load_tools([\"llm-math\"], llm=llm) + [ddg_search]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "agent.run(\"ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ê²€ìƒ‰í•˜ê³ , 256ì˜ ì œê³±ê·¼ì„ ê³„ì‚°í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be83575-7034-4962-bd7c-4a1b9235a1c1",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 02. Agent, AgentExecutor ìƒì„±\n",
    "- `Agent` = ì‹¤í–‰ ì „ëµ(ë„êµ¬ ì„ íƒ ë°©ì‹)\n",
    "- `AgentExecutor` = Agent + Tool ì‹¤í–‰ ê´€ë¦¬ì\n",
    "- `invoke({\"input\": ...})` ë¡œ ì‹¤í–‰\n",
    "- `initialize_agent` vs `AgentExecutor`\n",
    "  - ì „ìëŠ” ë¹ ë¥¸ ì´ˆê¸°í™”\n",
    "  - í›„ìëŠ” ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696bae70-3814-40be-a81d-307ff8d061ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `sqrt(256)`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 16.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `3^4`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 81\u001b[0m\u001b[32;1m\u001b[1;3m256ì˜ ì œê³±ê·¼ì€ 16ì´ê³ , 3ì˜ 4ì œê³±ì€ 81ì…ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '256ì˜ ì œê³±ê·¼ì€ ë­ì•¼? ê·¸ë¦¬ê³  3^4ëŠ”?',\n",
       " 'output': '256ì˜ ì œê³±ê·¼ì€ 16ì´ê³ , 3ì˜ 4ì œê³±ì€ 81ì…ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent, load_tools\n",
    "\n",
    "# 1) LLM ì¤€ë¹„\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 2) ì‚¬ìš©í•  íˆ´ \n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# 3) í”„ë¡¬í”„íŠ¸: ë°˜ë“œì‹œ agent_scratchpad ìë¦¬ í¬í•¨!\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# 4) í•¨ìˆ˜í˜• ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# 5) ì‹¤í–‰ê¸°\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 6) í˜¸ì¶œ\n",
    "executor.invoke({\"input\": \"256ì˜ ì œê³±ê·¼ì€ ë­ì•¼? ê·¸ë¦¬ê³  3^4ëŠ”?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7e8ae-1612-4c24-92a5-c1e21468672b",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 03. ì¤‘ê°„ë‹¨ê³„ ìŠ¤íŠ¸ë¦¬ë°\n",
    "- `streaming=True` ì„¤ì • â†’ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "- `AgentStreamParser` í™œìš© â†’ **Tool ì„ íƒ, Thought, Observation** ë‹¨ê³„ë³„ ì¶”ì  ê°€ëŠ¥\n",
    "- ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ì— ìœ ìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44158e25-68a2-4fd5-9582-fa1e58b3e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `sqrt(3)`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 1.7320508075688772\u001b[0m3ì˜ ì œê³±ê·¼ì€ 1.7320508075688772 ì…ë‹ˆë‹¤.\u001b[32;1m\u001b[1;3m3ì˜ ì œê³±ê·¼ì€ 1.7320508075688772 ì…ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '3ì˜ ì œê³±ê·¼ì€?', 'output': '3ì˜ ì œê³±ê·¼ì€ 1.7320508075688772 ì…ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent ì˜ ì¤‘ê°„ë‹¨ê³„ ìŠ¤íŠ¸ë¦¬ë° (AgentStreamParser)\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "streaming_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "agent = create_openai_functions_agent(streaming_llm, tools, prompt)\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "executor.invoke({\"input\": \"3ì˜ ì œê³±ê·¼ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b773e8-5063-468a-bcf8-be5d5bfaab30",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 04. Agent ë©”ëª¨ë¦¬ ì¶”ê°€\n",
    "- ê¸°ë³¸ AgentëŠ” ìƒíƒœ ì—†ìŒ â†’ ë©€í‹°í„´ ëŒ€í™” ë¶ˆê°€\n",
    "- `ConversationBufferMemory` ì¶”ê°€ â†’ ì´ì „ ëŒ€í™” ì €ì¥\n",
    "- ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ì ìš© ê°€ëŠ¥:\n",
    "  - BufferMemory\n",
    "  - SummaryMemory\n",
    "  - TokenBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823c5277-dd95-4065-936c-af2ee38b2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mì•ˆë…•í•˜ì„¸ìš”, DataWizarddë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3më‹¹ì—°íˆ DataWizarddë‹˜ì´ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ë‹¹ì—°íˆ DataWizarddë‹˜ì´ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent, load_tools\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# íˆ´ì€ ì˜ˆì‹œë¡œ llm-mathë§Œ\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ì— chat_historyì™€ agent_scratchpad ë‘˜ ë‹¤ ë°˜ë“œì‹œ í¬í•¨!\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),          # â† ë©”ëª¨ë¦¬ ì£¼ì… ì§€ì \n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),      # â† ì—ì´ì „íŠ¸ ì¤‘ê°„ ë‹¨ê³„ ê¸°ë¡\n",
    "])\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# ê¸°ì¡´ ë©”ëª¨ë¦¬ì™€ í‚¤ ì´ë¦„ ë§ì¶”ê¸°\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "\n",
    "executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "\n",
    "executor.invoke({\"input\": \"ë‚´ ì´ë¦„ì€ DataWizarddì•¼\"})\n",
    "print(executor.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"})[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e2604-cae9-406b-85f0-d233b8e46425",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 05. ë‹¤ì–‘í•œ LLM ê¸°ë°˜ Agent\n",
    "- LangChainì€ ì—¬ëŸ¬ LLM Provider ì§€ì›\n",
    "- **OpenAI, Anthropic(Claude), Google(Gemini), TogetherAI, Ollama** ë“±\n",
    "- ë™ì¼í•œ Agent êµ¬ì¡°ì— ë‹¤ë¥¸ LLM ë°”ì¸ë”©ë§Œ êµì²´ â†’ í˜¸í™˜ì„± ë†’ìŒ\n",
    "- ğŸ‘‰ ìƒí™©/ë¹„ìš©/ì„±ëŠ¥ ìš”êµ¬ì— ë”°ë¼ LLM êµì²´ ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4079144b-4992-4ea4-a26a-fc31b96b0515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ë‹¤ì–‘í•˜ê²Œ êµì²´ ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì–‘í•œ LLM ì„ í™œìš©í•œ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "\n",
    "# OpenAI GPT\n",
    "gpt_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Anthropic Claude (ì˜ˆì‹œ: langchain-anthropic í•„ìš”)\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# claude_llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "# Google Gemini (ì˜ˆì‹œ: langchain-google-genai í•„ìš”)\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# TogetherAI\n",
    "# from langchain_community.chat_models import ChatTogether\n",
    "# together_llm = ChatTogether(model=\"together/gpt-neoxt\")\n",
    "\n",
    "# Ollama (ë¡œì»¬ ì‹¤í–‰)\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# ollama_llm = ChatOllama(model=\"llama2\")\n",
    "\n",
    "print(\"LLM ë‹¤ì–‘í•˜ê²Œ êµì²´ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192333d5-5fea-459e-9d1f-2fb81b765bff",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 06. iter() & Human-in-the-loop\n",
    "- `executor.iter()` â†’ Agent ì‹¤í–‰ ê³¼ì •ì„ ë‹¨ê³„ë³„ ë°˜í™˜\n",
    "- ê° ë‹¨ê³„: Thought â†’ Action â†’ Observation\n",
    "- Human-in-the-loop:\n",
    "  - ì‹¤í–‰ ì¤‘ê°„ì— ì‚¬ëŒì´ä»‹å…¥í•´ ê²°ê³¼ ìˆ˜ì •/ê²°ì • ê°€ëŠ¥\n",
    "  - ë³´ì•ˆ/í’ˆì§ˆ ìš”êµ¬ê°€ ë†’ì€ ì›Œí¬í”Œë¡œìš°ì— ì í•©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e5200d-6171-4621-a3b1-5c81bc5c34c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new None chain...\u001b[0m\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\u001b[32;1m\u001b[1;3mëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ë‹¨ê³„ ì¶œë ¥: {'output': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.', 'messages': [AIMessage(content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\langchain\\chains\\base.py:487: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'messages']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  self.memory.save_context(inputs, outputs)\n"
     ]
    }
   ],
   "source": [
    "# iter() í•¨ìˆ˜ë¡œ ë‹¨ê³„ë³„ ì¶œë ¥ê³¼ Human-in-the-loop\n",
    "\n",
    "for step in executor.iter({\"input\": \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"}):\n",
    "    print(\"ë‹¨ê³„ ì¶œë ¥:\", step)\n",
    "    # ì‚¬ëŒì´ ì¤‘ê°„ì— intervention ê°€ëŠ¥ (ì˜ˆ: Tool ê²°ê³¼ ìˆ˜ì •)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f30480-60a4-4a6f-8498-424a207b7468",
   "metadata": {},
   "source": [
    "# âœ… ìµœì¢… ì •ë¦¬\n",
    "- **Binding Tools** â†’ Agent ê¸°ëŠ¥ í™•ì¥\n",
    "- **Agent & Executor** â†’ ì „ëµ + ì‹¤í–‰ ê´€ë¦¬\n",
    "- **Streaming & Parser** â†’ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë‹ˆí„°ë§\n",
    "- **Memory ì¶”ê°€** â†’ ë©€í‹°í„´ ëŒ€í™” ì§€ì›\n",
    "- **ë‹¤ì–‘í•œ LLM êµì²´** â†’ GPT, Claude, Gemini, Together, Ollama\n",
    "- **iter()** â†’ ë‹¨ê³„ë³„ ì‹¤í–‰ í™•ì¸ + Human-in-the-loopä»‹å…¥\n",
    "\n",
    "ğŸ‘‰ AgentëŠ” LLMì„ **ë„êµ¬ í™œìš© ê°€ëŠ¥í•œ ì§€ëŠ¥ì  ì‹¤í–‰ì**ë¡œ í™•ì¥í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
