{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e653993f-2d4a-45d7-929b-93f5a222480c",
   "metadata": {},
   "source": [
    "### 📌 LangServe 개요\n",
    "- LangChain Expression Language(LCEL)로 만든 체인/그래프/Agent 등을 **API 서버로 배포**하기 위한 도구\n",
    "- 내부적으로 **FastAPI** + **Uvicorn** 기반\n",
    "- 장점:\n",
    "  - LangChain에서 만든 체인을 바로 서빙 가능\n",
    "  - OpenAI API와 비슷한 호출 인터페이스 제공 (`/invoke`, `/stream`, `/batch`)\n",
    "  - **Observability**: LangSmith와 연동하여 추적 가능\n",
    "- 주요 사용처:\n",
    "  - RAG, Agent, Chatbot 모델을 REST API로 제공\n",
    "  - 사내 서비스/대시보드/앱에서 쉽게 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cffe940-7360-435b-883f-b42e3bc5f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 설치\n",
    "# # pip install \"langserve[all]\" fastapi uvicorn\n",
    "\n",
    "## LangServe로 모델 서빙하기\n",
    "\n",
    "# from fastapi import FastAPI\n",
    "# from langserve import add_routes\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.schema import StrOutputParser\n",
    "\n",
    "# # 1) 체인 정의 (LangChain LCEL)\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"당신은 친절한 AI 비서입니다.\"),\n",
    "#     (\"human\", \"{question}\")\n",
    "# ])\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# # 2) FastAPI 앱 생성\n",
    "# app = FastAPI(\n",
    "#     title=\"LangServe Example\",\n",
    "#     version=\"1.0\",\n",
    "#     description=\"LangServe로 배포한 예시 체인\"\n",
    "# )\n",
    "\n",
    "# # 3) 체인을 API 엔드포인트로 추가\n",
    "# add_routes(app, chain, path=\"/chat\")\n",
    "\n",
    "# # 4) 실행 (터미널)\n",
    "# # uvicorn filename:app --reload --port 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154eb90e-795b-43de-b321-1e217f3599b5",
   "metadata": {},
   "source": [
    "### 📌 서빙 구조\n",
    "- `add_routes(app, chain, path=\"/chat\")`\n",
    "  - `/chat/invoke` : 단일 입력 → 출력\n",
    "  - `/chat/stream` : 스트리밍 출력 (토큰 단위)\n",
    "  - `/chat/batch`  : 여러 입력 동시에 처리\n",
    "- 체인은 **LCEL**로 정의된 모든 객체 (프롬프트 → LLM → 파서)를 지원\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba5c33-7524-4aa3-bda6-12314cf1daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python 클라이언트에서 호출\n",
    "# from langserve.client import RemoteRunnable\n",
    "\n",
    "# # LangServe 서버 주소 (로컬 또는 배포 서버)\n",
    "# remote_chain = RemoteRunnable(\"http://localhost:8000/chat\")\n",
    "\n",
    "# # 단일 호출\n",
    "# resp = remote_chain.invoke({\"question\": \"LangServe가 뭐야?\"})\n",
    "# print(\"응답:\", resp)\n",
    "\n",
    "# # 배치 호출\n",
    "# resps = remote_chain.batch([\n",
    "#     {\"question\": \"LangChain이 뭐야?\"},\n",
    "#     {\"question\": \"LangGraph가 뭐야?\"}\n",
    "# ])\n",
    "# print(resps)\n",
    "\n",
    "# # 스트리밍 호출\n",
    "# for chunk in remote_chain.stream({\"question\": \"토큰 단위로 답변해줘\"}):\n",
    "#     print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10fcaf9-abcb-4a3d-865c-28a44835d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HTTP REST 호출\n",
    "# # invoke (단일 입력)\n",
    "# curl http://localhost:8000/chat/invoke \\\n",
    "#     -H \"Content-Type: application/json\" \\\n",
    "#     -d '{\"input\": {\"question\": \"LangServe란?\"}}'\n",
    "\n",
    "# # batch (여러 입력)\n",
    "# curl http://localhost:8000/chat/batch \\\n",
    "#     -H \"Content-Type: application/json\" \\\n",
    "#     -d '{\"inputs\": [{\"question\": \"LangChain?\"}, {\"question\": \"LangGraph?\"}]}'\n",
    "\n",
    "# # stream (스트리밍)\n",
    "# curl -N http://localhost:8000/chat/stream \\\n",
    "#     -H \"Content-Type: application/json\" \\\n",
    "#     -d '{\"input\": {\"question\": \"스트리밍 예시\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8868fd-c55f-467c-8eb9-05dc7a82af8a",
   "metadata": {},
   "source": [
    "## 프론트엔드/다른 서비스 연동\n",
    "- FastAPI 엔드포인트는 REST 규격이므로, **React, Vue, Next.js** 같은 프론트엔드에서 바로 호출 가능\n",
    "- 회사 내부 백엔드 서비스 (Flask, Django, Node.js 등)와도 쉽게 통합\n",
    "- LangServe는 LangChain Hub, LangSmith와 연동 가능 → 관리/모니터링 용이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90069f-35d9-4739-9a0c-257d4378ab84",
   "metadata": {},
   "source": [
    "## ✅ 최종 정리\n",
    "\n",
    "- LangServe = LangChain 체인을 쉽게 REST API로 서빙하는 도구\n",
    "\n",
    "- 서빙 절차:\n",
    "\n",
    "    - 체인 정의 (프롬프트 → LLM → 파서)\n",
    "\n",
    "    - add_routes(app, chain, path=\"...\")\n",
    "\n",
    "    - FastAPI + Uvicorn으로 실행\n",
    "\n",
    "- 사용 방법:\n",
    "\n",
    "    - Python 클라이언트(RemoteRunnable)\n",
    "\n",
    "    - REST API (invoke, batch, stream)\n",
    "\n",
    "- 활용 예시:\n",
    "\n",
    "    - 사내 RAG 검색기 API\n",
    "\n",
    "    - AI 챗봇 백엔드\n",
    "\n",
    "    - 데이터 분석 Agent 서빙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb8831-1f3c-4b5e-8e37-7704ca637522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
