{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251dc0ca-be14-4cf6-a412-328dd45e9e4f",
   "metadata": {},
   "source": [
    "### 📌 LangGraph 개요\n",
    "- **LangChain 기반의 Workflow Orchestration 라이브러리**\n",
    "- LLM + Tool + Memory + 조건부 분기 등을 **그래프 구조**로 표현\n",
    "- 핵심 개념:\n",
    "  - **State**: 노드 간 공유되는 상태 (TypedDict 등으로 정의)\n",
    "  - **Node**: 상태를 입력받아 가공하는 함수/LLM 호출/Tool\n",
    "  - **Edge**: 노드 간 연결 (조건부 분기 가능)\n",
    "  - **Compile**: 그래프를 실행 가능한 객체로 변환\n",
    "- 장점:\n",
    "  - 체인보다 **복잡한 워크플로우**를 유연하게 구성\n",
    "  - 디버깅/재실행/분기 제어가 용이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cdd3b14-427e-4b51-b413-4704d4eda8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 설치: pip install langgraph\n",
    "\n",
    "# from langgraph.graph import StateGraph, END\n",
    "\n",
    "# # 간단한 Hello World 그래프 예시\n",
    "# def hello_node(state):\n",
    "#     print(\"Hello, LangGraph!\")\n",
    "#     return state\n",
    "\n",
    "# # 그래프 정의\n",
    "# graph = StateGraph(dict)\n",
    "# graph.add_node(\"hello\", hello_node)\n",
    "# graph.set_entry_point(\"hello\")\n",
    "# graph.set_finish_point(\"hello\")\n",
    "\n",
    "# app = graph.compile()\n",
    "# app.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b51f8-eb64-4dc9-934c-38f10a8bcba2",
   "metadata": {},
   "source": [
    "### 📌 LangGraph 기본 구조\n",
    "- **State**: TypedDict로 명시적 타입 지정\n",
    "- **Node**: 상태를 받아서 가공 후 반환\n",
    "- **Edge**: 단순 연결 or 조건부 연결\n",
    "- **Compile**: `graph.compile()` 후 `.invoke()`로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18535cf2-8b1c-48dd-b175-a98fb3dce1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'LangGraph란?', 'answer': '답변: LangGraph란?에 대한 예시 응답'}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "# 상태 정의\n",
    "class MyState(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "# 노드 함수\n",
    "def answer_node(state: MyState):\n",
    "    state[\"answer\"] = f\"답변: {state['question']}에 대한 예시 응답\"\n",
    "    return state\n",
    "\n",
    "# 그래프 빌드\n",
    "graph = StateGraph(MyState)\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "graph.set_entry_point(\"answer\")\n",
    "graph.set_finish_point(\"answer\")\n",
    "\n",
    "app = graph.compile()\n",
    "print(app.invoke({\"question\": \"LangGraph란?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27747845-a7da-4e62-9df1-db650cc7b65b",
   "metadata": {},
   "source": [
    "### 📌 자주 쓰는 문법\n",
    "- **TypedDict**: 상태 타입 정의\n",
    "- **Annotated**: 상태 업데이트 방식 지정 (append 등)\n",
    "- **Reducer**: 여러 노드 결과를 누적 관리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9712c519-0e53-4899-b0ac-437d7eaf4090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': ['Hello!']}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Reducer: 상태 업데이트 방법 정의\n",
    "class State(TypedDict):\n",
    "    history: Annotated[list[str], \"append\"]\n",
    "\n",
    "def add_message(state: State):\n",
    "    state[\"history\"].append(\"Hello!\")\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"add\", add_message)\n",
    "graph.set_entry_point(\"add\")\n",
    "graph.set_finish_point(\"add\")\n",
    "\n",
    "app = graph.compile()\n",
    "print(app.invoke({\"history\": []}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792b3a8-f03c-4c57-95ef-3f55e3d90cc3",
   "metadata": {},
   "source": [
    "### 📌 챗봇 구현\n",
    "- 상태 = `messages` (대화 이력)\n",
    "- 노드 = LLM 호출\n",
    "- 실행 = HumanMessage 입력 → AIMessage 응답\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648cfa1a-aba2-4085-bd23-187d8b1d35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b4ebc2-68f9-4a2a-bc59-9b9f5a6b48c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='안녕 LangGraph?', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 14, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C9w8JsXb3su4KODfLMrRtun6kwv84', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--11490e46-0296-43bc-97c7-4244ed7c4c4d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 21, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "def llm_node(state: ChatState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    state[\"messages\"].append(response)\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat\", llm_node)\n",
    "graph.set_entry_point(\"chat\")\n",
    "graph.set_finish_point(\"chat\")\n",
    "\n",
    "app = graph.compile()\n",
    "print(app.invoke({\"messages\": [HumanMessage(content=\"안녕 LangGraph?\")]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0ede2-06e2-4fa7-9f0e-9c00fb0b0564",
   "metadata": {},
   "source": [
    "### 📌 Function Calling + Conditional Edge\n",
    "- LLM의 함수 호출(Function Calling)과 도구 호출을 노드로 구성\n",
    "- 조건에 따라 다른 노드로 이동 (if-else 구조를 Edge로 표현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0182df1-0793-4329-94c5-334ebe803d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '오늘 날씨 어때?', 'answer': '오늘은 맑습니다.'}\n",
      "{'question': 'LangGraph가 뭐야?', 'answer': '일반적인 질문 답변입니다.'}\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# 1) 상태 정의\n",
    "class MyState(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "# 2) 라우팅 함수 (분기 결정)\n",
    "def decide_route(state: MyState) -> str:\n",
    "    return \"weather\" if \"날씨\" in state[\"question\"] else \"general\"\n",
    "\n",
    "# 3) 작업 노드\n",
    "def weather_node(state: MyState):\n",
    "    state[\"answer\"] = \"오늘은 맑습니다.\"\n",
    "    return state\n",
    "\n",
    "def general_node(state: MyState):\n",
    "    state[\"answer\"] = \"일반적인 질문 답변입니다.\"\n",
    "    return state\n",
    "\n",
    "# 4) 그래프 구성\n",
    "graph = StateGraph(MyState)\n",
    "\n",
    "# (1) 라우터 노드: 상태만 통과시키는 no-op\n",
    "def router(state: MyState): \n",
    "    return state\n",
    "\n",
    "graph.add_node(\"router\", router)\n",
    "graph.add_node(\"weather\", weather_node)\n",
    "graph.add_node(\"general\", general_node)\n",
    "\n",
    "# (2) 라우터에서 조건부 분기\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    decide_route,                 # 분기 함수: \"weather\" 또는 \"general\" 반환\n",
    "    {\"weather\": \"weather\", \"general\": \"general\"}  # 반환값 → 노드 매핑\n",
    ")\n",
    "\n",
    "# (3) 종료 엣지\n",
    "graph.add_edge(\"weather\", END)\n",
    "graph.add_edge(\"general\", END)\n",
    "\n",
    "# (4) 진입 지점\n",
    "graph.set_entry_point(\"router\")\n",
    "\n",
    "# 5) 컴파일 & 실행\n",
    "app = graph.compile()\n",
    "print(app.invoke({\"question\": \"오늘 날씨 어때?\"}))\n",
    "print(app.invoke({\"question\": \"LangGraph가 뭐야?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd0dbd-efa6-41db-9f74-ab6065aea859",
   "metadata": {},
   "source": [
    "### 📌 Checkpointer (메모리)\n",
    "- LangGraph는 **Checkpointer**로 실행 상태 저장\n",
    "- `thread_id` 별로 대화 맥락 유지 가능\n",
    "- MemorySaver = 기본 메모리형 저장소\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6efaa5-d219-4d40-a440-ca46699fa1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차 응답: 저는 AI 어시스턴트이며, 이름은 없습니다. 어떻게 도와드릴까요?\n",
      "2차 응답: 당신은 \"너 이름이 뭐야?\"라고 물었습니다.\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph langchain-openai\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 1) 상태에 'messages'를 정의하고, 누적 방식을 add_messages로 지정\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 2) LLM 노드: 전체 messages를 넣어 답변 받고, 새 메시지로 반환 (리듀서가 자동 append)\n",
    "def chat_node(state: ChatState):\n",
    "    ai_msg = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [ai_msg]}  # ← 반환을 리스트로! (리듀서가 기존에 append함)\n",
    "\n",
    "# 3) 그래프 구성\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat\", chat_node)\n",
    "graph.add_edge(START, \"chat\")\n",
    "graph.add_edge(\"chat\", END)\n",
    "\n",
    "# 4) 체크포인터 연결\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# 5) 동일 thread_id로 두 번 호출 → 두 번째 호출에서 과거 대화가 자동 주입\n",
    "cfg = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "r1 = app.invoke({\"messages\": [HumanMessage(content=\"너 이름이 뭐야?\")]}, config=cfg)\n",
    "print(\"1차 응답:\", r1[\"messages\"][-1].content)\n",
    "\n",
    "r2 = app.invoke({\"messages\": [HumanMessage(content=\"내가 방금 뭐라고 했지?\")]}, config=cfg)\n",
    "print(\"2차 응답:\", r2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e70ba-c005-45e4-9984-9ce7433c004e",
   "metadata": {},
   "source": [
    "### 📌 Stream 모드 & Interrupt\n",
    "- `.stream()` → 노드별 중간 결과 확인\n",
    "- **Interrupt** → 특정 지점에서 실행 중단, 사람이 개입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67ae6a8d-88e7-4dc9-bbcf-38060c694e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중간 업데이트: {'chat': {'messages': [AIMessage(content='LangGraph는 언어 간 상호 작용을 시각적으로 나타내는 그래프 형식의 도구입니다. 이 도구는 다양한 언어 간의 관계를 시각적으로 이해하고 분석하는 데 도움을 줄 수 있습니다. LangGraph를 사용하면 언어 간의 공통점과 차이점을 쉽게 파악할 수 있으며, 언어 간의 상호 작용을 보다 효과적으로 이해할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 147, 'prompt_tokens': 12, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C9wCmL2xe5GTCjPjTrEIpJFUijODR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b8c10ee7-f056-4e22-ba5d-a4057a8c4ec4-0', usage_metadata={'input_tokens': 12, 'output_tokens': 147, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "# 예: ChatState(messages=...) 패턴 + MemorySaver 사용 중\n",
    "cfg = {\"configurable\": {\"thread_id\": \"session-1\"}}  # 세션 식별자\n",
    "\n",
    "# 기본 스트림 (각 노드의 출력 묶음 단위)\n",
    "for update in app.stream({\"messages\": [{\"type\":\"human\",\"content\":\"LangGraph란?\"}]}, config=cfg):\n",
    "    print(\"중간 업데이트:\", update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a34523-a0b8-4f0c-8959-5da832a9a12c",
   "metadata": {},
   "source": [
    "### 📌 Naive RAG\n",
    "- **전통적 구조**:\n",
    "  1. Retriever로 문서 검색\n",
    "  2. Generator로 LLM 응답 생성\n",
    "- LangGraph는 이 흐름을 **시각적으로, 모듈적으로 구성** 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af75c46f-8899-430b-9ca1-2ace14cd743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_5840\\1378141614.py:29: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(state[\"question\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 답변 ==\n",
      "LangGraph는 그래프 기반 LLM 워크플로우 오케스트레이션 라이브러리입니다.\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph langchain-openai langchain-community faiss-cpu\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1) 데이터 & 검색기 준비 -------------------------------------------------------\n",
    "texts = [\n",
    "    \"LangGraph는 그래프 기반 LLM 워크플로우 오케스트레이션 라이브러리다.\",\n",
    "    \"RAG는 검색(Retrieval)과 생성(Generation)을 결합한 접근법이다.\",\n",
    "    \"LangChain은 LLM 앱 개발을 쉽게 하는 프레임워크다.\",\n",
    "]\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vs = FAISS.from_texts(texts, emb)\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 3})  # ← NameError 해결 포인트\n",
    "\n",
    "# 2) LLM 준비 -------------------------------------------------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 3) 상태 정의 ------------------------------------------------------------------\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "# 4) 노드 정의 ------------------------------------------------------------------\n",
    "def retrieve_node(state: RAGState) -> RAGState:\n",
    "    docs = retriever.get_relevant_documents(state[\"question\"])\n",
    "    ctx = \"\\n\".join(d.page_content for d in docs)\n",
    "    state[\"context\"] = ctx\n",
    "    return state\n",
    "\n",
    "def generate_node(state: RAGState) -> RAGState:\n",
    "    prompt = f\"\"\"당신은 한국어 도우미입니다.\n",
    "질문: {state['question']}\n",
    "문맥:\n",
    "{state['context']}\n",
    "\n",
    "문맥을 근거로 간결하게 답변하세요.\"\"\"\n",
    "    state[\"answer\"] = llm.invoke(prompt).content\n",
    "    return state\n",
    "\n",
    "# 5) 그래프 구성 ----------------------------------------------------------------\n",
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"generate\", generate_node)\n",
    "graph.add_edge(START, \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# 6) 실행 -----------------------------------------------------------------------\n",
    "out = app.invoke({\"question\": \"LangGraph란?\"})\n",
    "print(\"== 답변 ==\")\n",
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d90f51-9374-427f-8a59-f36cb1e49b86",
   "metadata": {},
   "source": [
    "### 📌 할루시네이션 평가 모듈\n",
    "- 응답에 근거 문맥이 포함되지 않으면 경고 추가\n",
    "- **품질 관리 노드**로 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2315fca8-ae77-4b8c-abb4-845b0502cf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph는 그래프 기반 LLM 워크플로 오케스트레이션 라이브러리이다.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# --- 검색/LLM 준비 ---\n",
    "texts = [\n",
    "    \"LangGraph는 그래프 기반 LLM 워크플로 오케스트레이션 라이브러리다.\",\n",
    "    \"RAG는 검색과 생성을 결합한 접근법이다.\",\n",
    "    \"LangChain은 LLM 앱 개발을 쉽게 한다.\",\n",
    "]\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vs = FAISS.from_texts(texts, emb)\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# --- 상태 & 노드 정의 ---\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "def retrieve_node(state: RAGState) -> RAGState:\n",
    "    docs = retriever.get_relevant_documents(state[\"question\"])\n",
    "    state[\"context\"] = \"\\n\".join(d.page_content for d in docs)\n",
    "    return state\n",
    "\n",
    "def generate_node(state: RAGState) -> RAGState:\n",
    "    prompt = f\"\"\"질문: {state['question']}\n",
    "문맥:\n",
    "{state['context']}\n",
    "\n",
    "문맥을 근거로 간결하게 답하세요.\"\"\"\n",
    "    state[\"answer\"] = llm.invoke(prompt).content\n",
    "    return state\n",
    "\n",
    "def hallucination_check(state: RAGState) -> RAGState:\n",
    "    # 아주 단순한 데모용 규칙 (실전은 RAGAS/LLM 검증 등 권장)\n",
    "    if \"LangGraph\" not in state[\"answer\"]:\n",
    "        state[\"answer\"] += \" (문맥과 무관한 내용일 수 있음)\"\n",
    "    return state\n",
    "\n",
    "# --- 그래프 구성(compile 전에 전부 추가) ---\n",
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"generate\", generate_node)\n",
    "graph.add_node(\"check\", hallucination_check)\n",
    "\n",
    "graph.add_edge(START, \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"check\")\n",
    "graph.add_edge(\"check\", END)  # ← 종료는 END로 두는 편이 최신 패턴에 맞음\n",
    "\n",
    "# 반드시 여기서 컴파일\n",
    "app = graph.compile()\n",
    "\n",
    "# 실행\n",
    "out = app.invoke({\"question\": \"LangGraph란?\"})\n",
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a0d65-b83f-4dce-9b85-305eba219c0c",
   "metadata": {},
   "source": [
    "### 📌 웹 검색 노드\n",
    "- Retriever 외부에 **실시간 검색 노드** 추가 가능\n",
    "- 최신 정보 기반 RAG 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e09ab148-4c67-4c4a-8206-de7e7fa140cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph는 언어 간 상호 연결성을 시각적으로 보여주는 그래프 시각화 도구입니다. LangGraph는 그래프 기반 LLM 워크플로 오케스트레이션 라이브러리이며, LangChain은 LLM 앱 개발을 쉽게 도와주는 도구입니다. RAG는 검색과 생성을 결합한 접근법을 사용하는 도구입니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요시 설치: pip install duckduckgo-search langgraph langchain-openai langchain-community faiss-cpu\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# ----- 0) 리소스 준비 -----\n",
    "texts = [\n",
    "    \"LangGraph는 그래프 기반 LLM 워크플로 오케스트레이션 라이브러리다.\",\n",
    "    \"RAG는 검색과 생성을 결합한 접근법이다.\",\n",
    "    \"LangChain은 LLM 앱 개발을 쉽게 한다.\",\n",
    "]\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vs = FAISS.from_texts(texts, emb)\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "ddg = DuckDuckGoSearchRun()\n",
    "\n",
    "# ----- 1) 상태 정의 -----\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "# ----- 2) 노드 정의 -----\n",
    "def rewrite_node(state: RAGState) -> RAGState:\n",
    "    # (옵션) 쿼리 재작성: 필요 없으면 이 노드/엣지 제거해도 됩니다.\n",
    "    new_q = llm.invoke(f\"다음 질문을 웹/문서 검색에 적합하게 한 문장으로 재작성: {state['question']}\").content\n",
    "    state[\"question\"] = new_q.strip()\n",
    "    return state\n",
    "\n",
    "def websearch_node(state: RAGState) -> RAGState:\n",
    "    # DuckDuckGo 웹검색 결과 문자열(요약)을 context에 추가\n",
    "    result = ddg.run(state[\"question\"])\n",
    "    state[\"context\"] = (state.get(\"context\") or \"\") + (\"\\n\" if state.get(\"context\") else \"\") + result\n",
    "    return state\n",
    "\n",
    "def retrieve_node(state: RAGState) -> RAGState:\n",
    "    docs = retriever.get_relevant_documents(state[\"question\"])\n",
    "    ctx = \"\\n\".join(d.page_content for d in docs)\n",
    "    state[\"context\"] = (state.get(\"context\") + \"\\n\" if state.get(\"context\") else \"\") + ctx\n",
    "    return state\n",
    "\n",
    "def generate_node(state: RAGState) -> RAGState:\n",
    "    prompt = f\"\"\"당신은 한국어 도우미입니다.\n",
    "질문: {state['question']}\n",
    "문맥:\n",
    "{state['context']}\n",
    "\n",
    "문맥을 근거로 간결하고 사실적으로 답하세요.\"\"\"\n",
    "    state[\"answer\"] = llm.invoke(prompt).content\n",
    "    return state\n",
    "\n",
    "def hallucination_check(state: RAGState) -> RAGState:\n",
    "    # 데모용 간단 검증\n",
    "    if \"LangGraph\" not in state[\"answer\"] and \"LangGraph\" in state[\"context\"]:\n",
    "        state[\"answer\"] += \" (문맥과 무관할 수 있음)\"\n",
    "    return state\n",
    "\n",
    "# ----- 3) 그래프 구성 -----\n",
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"rewrite\", rewrite_node)          # (옵션)\n",
    "graph.add_node(\"websearch\", websearch_node)      # 새 노드\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"generate\", generate_node)\n",
    "graph.add_node(\"check\", hallucination_check)\n",
    "\n",
    "# 흐름: START → (rewrite) → websearch → retrieve → generate → check → END\n",
    "graph.add_edge(START, \"rewrite\")\n",
    "graph.add_edge(\"rewrite\", \"websearch\")\n",
    "graph.add_edge(\"websearch\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"check\")\n",
    "graph.add_edge(\"check\", END)\n",
    "\n",
    "# ----- 4) 반드시 여기서 컴파일! -----\n",
    "app = graph.compile()\n",
    "\n",
    "# ----- 5) 실행 -----\n",
    "out = app.invoke({\"question\": \"LangGraph란?\"})\n",
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac765cc-6fcb-4c62-9052-caee8a2b6399",
   "metadata": {},
   "source": [
    "### 📌 쿼리 재작성 노드\n",
    "- 원본 질문을 검색 친화적으로 재작성\n",
    "- 검색 Recall 향상 → RAG 성능 개선\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "777fad22-e943-4bd6-8e57-62162bfb5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph는 Multi-Agent 특화 프레임워크로, 다중 에이전트 시스템을 구축할 수 있게 해주는 도구입니다. 각 에이전트는 특정 목표를 향해 자율적으로 행동하며, 다른 에이전트들과 협업하여 복잡한 문제를 해결할 수 있습니다. LangGraph는 AI의 사고 흐름을 그릴 수 있는 도구로, 복잡한 AI 시스템을 쉽게 만들어주는 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# pip install langgraph langchain-openai langchain-community faiss-cpu duckduckgo-search\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# 리소스\n",
    "texts = [\n",
    "    \"LangGraph는 그래프 기반 LLM 워크플로 오케스트레이션 라이브러리다.\",\n",
    "    \"RAG는 검색과 생성을 결합한 접근법이다.\",\n",
    "    \"LangChain은 LLM 앱 개발을 쉽게 한다.\",\n",
    "]\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vs = FAISS.from_texts(texts, emb)\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "ddg = DuckDuckGoSearchRun()\n",
    "\n",
    "# 상태\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "# 노드\n",
    "def rewrite_query(state: RAGState) -> RAGState:\n",
    "    state[\"question\"] = llm.invoke(\n",
    "        f\"다음 질문을 검색에 최적화된 쿼리로 다시 써줘: {state['question']}\"\n",
    "    ).content.strip()\n",
    "    return state\n",
    "\n",
    "def websearch_node(state: RAGState) -> RAGState:\n",
    "    result = ddg.run(state[\"question\"])\n",
    "    state[\"context\"] = (state.get(\"context\") + \"\\n\" if state.get(\"context\") else \"\") + result\n",
    "    return state\n",
    "\n",
    "def retrieve_node(state: RAGState) -> RAGState:\n",
    "    docs = retriever.get_relevant_documents(state[\"question\"])\n",
    "    ctx = \"\\n\".join(d.page_content for d in docs)\n",
    "    state[\"context\"] = (state.get(\"context\") + \"\\n\" if state.get(\"context\") else \"\") + ctx\n",
    "    return state\n",
    "\n",
    "def generate_node(state: RAGState) -> RAGState:\n",
    "    prompt = f\"\"\"당신은 한국어 도우미입니다.\n",
    "질문: {state['question']}\n",
    "문맥:\n",
    "{state['context']}\n",
    "\n",
    "문맥을 근거로 간결하고 사실적으로 답하세요.\"\"\"\n",
    "    state[\"answer\"] = llm.invoke(prompt).content\n",
    "    return state\n",
    "\n",
    "def hallucination_check(state: RAGState) -> RAGState:\n",
    "    if \"LangGraph\" not in state[\"answer\"] and \"LangGraph\" in state.get(\"context\", \"\"):\n",
    "        state[\"answer\"] += \" (문맥과 무관할 수 있음)\"\n",
    "    return state\n",
    "\n",
    "# 그래프 구성 (모두 추가 → 마지막에 컴파일)\n",
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"rewrite\", rewrite_query)\n",
    "graph.add_node(\"websearch\", websearch_node)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"generate\", generate_node)\n",
    "graph.add_node(\"check\", hallucination_check)\n",
    "\n",
    "graph.add_edge(START, \"rewrite\")\n",
    "graph.add_edge(\"rewrite\", \"websearch\")\n",
    "graph.add_edge(\"websearch\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"check\")\n",
    "graph.add_edge(\"check\", END)\n",
    "\n",
    "app = graph.compile()  # ← 한 번만 컴파일\n",
    "\n",
    "# 실행\n",
    "print(app.invoke({\"question\": \"LangGraph란?\"})[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209b934-e393-4cfe-b8ab-f5e93d7aeedb",
   "metadata": {},
   "source": [
    "## ✅ 최종 정리\n",
    "\n",
    "- LangGraph 개요: State, Node, Edge, Compile → 체인보다 강력한 워크플로우 엔진\n",
    "\n",
    "- 핵심 기능: TypedDict, Annotated, Reducer / Memory(Checkpointer) / Stream / Interrupt / Replay\n",
    "\n",
    "- 구조 설계: Naive RAG → 평가 모듈 → 웹검색 → 쿼리 재작성 등 모듈 단위 확장 가능\n",
    "\n",
    "- 👉 LangGraph는 단순 체인에서 한 단계 더 나아가, 복잡한 RAG/에이전트 시스템을 엔지니어링하는 필수 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d9f57-94e7-40eb-9b09-a0c6e1842db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
