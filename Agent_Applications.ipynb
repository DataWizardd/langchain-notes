{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf67a339-a2d5-49f8-8a97-cba7989855fd",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Agentic RAG\n",
    "- **ê¸°ì¡´ RAG**: `Retriever â†’ LLM` ì§ë ¬ íŒŒì´í”„ë¼ì¸\n",
    "- **Agentic RAG**: LLMì´ ìŠ¤ìŠ¤ë¡œ Tool í˜¸ì¶œ(ê²€ìƒ‰, ë¦¬ë­í‚¹ ë“±) ê²°ì •ì„ ë‚´ë¦¼\n",
    "- ì¥ì :\n",
    "  - ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ â€œê²€ìƒ‰â€ vs â€œì§ì ‘ ë‹µë³€â€ ì„ íƒ ê°€ëŠ¥\n",
    "  - ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ì—¬ëŸ¬ ë²ˆ íˆ´ í˜¸ì¶œ ê°€ëŠ¥\n",
    "- í•µì‹¬ êµ¬ì„±:\n",
    "  - Retrieverë¥¼ Toolë¡œ ë“±ë¡\n",
    "  - LLM Agentê°€ Toolì„ í˜¸ì¶œí•´ ì¦ê±° ë¬¸ì„œ í™•ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ba8903-5de7-43f6-9c01-57fcf332ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7266da2e-7119-48fe-88f7-6340aa9d7d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_19000\\3851514298.py:36: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_19000\\3851514298.py:39: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"LangChainê³¼ RAGì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•´ì¤˜\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the KnowledgeBase to search for information on the relationship between LangChain and RAG.\n",
      "Action: KnowledgeBase\n",
      "Action Input: \"Relationship between LangChain and RAG\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_19000\\3851514298.py:24: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mRAGëŠ” ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•˜ëŠ” ì ‘ê·¼ ë°©ì‹ì´ë‹¤.\n",
      "LangChainì€ LLM ê¸°ë°˜ ì•± ê°œë°œì„ ì‰½ê²Œ í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë‹¤.\n",
      "AgentëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information gathered, LangChain is a framework that makes it easy to develop apps based on LLM, while RAG is an approach that combines search and generation. LangChain may be used by agents to perform complex tasks. \n",
      "Final Answer: LangChain is a framework for LLM-based app development, while RAG is an approach that combines search and generation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for LLM-based app development, while RAG is an approach that combines search and generation.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agentic RAG: ê²€ìƒ‰ê¸° + ë¦¬ë­ì»¤ + LLM Agent ì¡°í•©\n",
    "# pip install langchain langchain-openai langchain-community faiss-cpu\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# 1) LLM, ì„ë² ë”© ì¤€ë¹„\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 2) ë¬¸ì„œ ì¤€ë¹„ (ê°„ë‹¨ ì˜ˆì‹œ)\n",
    "docs = [\n",
    "    \"LangChainì€ LLM ê¸°ë°˜ ì•± ê°œë°œì„ ì‰½ê²Œ í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë‹¤.\",\n",
    "    \"RAGëŠ” ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•˜ëŠ” ì ‘ê·¼ ë°©ì‹ì´ë‹¤.\",\n",
    "    \"AgentëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\"\n",
    "]\n",
    "\n",
    "vectorstore = FAISS.from_texts(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3) ê²€ìƒ‰ê¸°ë¥¼ Agentì˜ Toolë¡œ ë°”ì¸ë”©\n",
    "def retriever_tool(query: str):\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    return \"\\n\".join([d.page_content for d in results])\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"KnowledgeBase\",\n",
    "        func=retriever_tool,\n",
    "        description=\"RAGìš© ë¬¸ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œë‹¤.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 4) Agent ì´ˆê¸°í™”\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# 5) ì‹¤í–‰\n",
    "agent.run(\"LangChainê³¼ RAGì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65487459-2d40-448e-8aa3-10cf29b859c7",
   "metadata": {},
   "source": [
    "### ğŸ“Œ CSV/Excel ë°ì´í„°ë¶„ì„ Agent\n",
    "- LangChainì€ **DataFrame Agent**ë¥¼ ì œê³µ â†’ LLMì´ íŒë‹¤ìŠ¤ ì—°ì‚°ì„ ìˆ˜í–‰\n",
    "- ì‚¬ìš© ì ˆì°¨:\n",
    "  1. CSV/Excelì„ Pandas DataFrameìœ¼ë¡œ ë¡œë“œ\n",
    "     - `pd.read_csv(\"íŒŒì¼.csv\")`\n",
    "     - `pd.read_excel(\"íŒŒì¼.xlsx\")`\n",
    "  2. `create_pandas_dataframe_agent(llm, df)`\n",
    "  3. ìì—°ì–´ ì§ˆë¬¸ â†’ Agentê°€ ë‚´ë¶€ì ìœ¼ë¡œ Python ì½”ë“œ ì‘ì„± & ì‹¤í–‰\n",
    "- ì¥ì :\n",
    "  - ë°ì´í„° í†µê³„/ì‹œê°í™”/ê·¸ë£¹ ì—°ì‚° ë“±ì„ ìì—°ì–´ë¡œ ì§ˆì˜\n",
    "- ì£¼ì˜:\n",
    "  - ë¯¼ê° ë°ì´í„° ì‚¬ìš© ì‹œ ë³´ì•ˆ ê³ ë ¤\n",
    "  - LLMì´ ì˜ëª»ëœ ì½”ë“œ ìƒì„± ì‹œ ì—ëŸ¬ ë°œìƒ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acfb279-4c02-4167-af66-cad55b0f43c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To calculate the average age, we need to find the mean of the 'ë‚˜ì´' column in the dataframe.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['ë‚˜ì´'].mean()\u001b[0m\u001b[36;1m\u001b[1;3m24.5\u001b[0m\u001b[32;1m\u001b[1;3mThe average age is 24.5 years old.\n",
      "Final Answer: 24.5 years\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "24.5 years\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: We need to find the student with the highest score.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI will use the python_repl_ast tool instead.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI will use the python_repl_ast tool instead.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI will use the python_repl_ast tool instead.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI apologize for the confusion. Let's try using the python_repl_ast tool again to get the correct answer.\n",
      "\n",
      "Question: ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ í•™ìƒì˜ ì´ë¦„ì€ ëˆ„êµ¬ì•¼?\n",
      "Thought: We need to find the student with the highest score.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI apologize for the inconvenience. Let's try using the python_repl_ast tool again to get the correct answer.\n",
      "\n",
      "Question: ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ í•™ìƒì˜ ì´ë¦„ì€ ëˆ„êµ¬ì•¼?\n",
      "Thought: We need to find the student with the highest score.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI apologize for the inconvenience. Let's try using the python_repl_ast tool again to get the correct answer.\n",
      "\n",
      "Question: ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ í•™ìƒì˜ ì´ë¦„ì€ ëˆ„êµ¬ì•¼?\n",
      "Thought: We need to find the student with the highest score.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI apologize for the inconvenience. Let's try using the python_repl_ast tool again to get the correct answer.\n",
      "\n",
      "Question: ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ í•™ìƒì˜ ì´ë¦„ì€ ëˆ„êµ¬ì•¼?\n",
      "Thought: We need to find the student with the highest score.\n",
      "Action: [python_repl_ast]\n",
      "Action Input: df[df['ì ìˆ˜'] == df['ì ìˆ˜'].max()]['ì´ë¦„'].values[0]\u001b[0m[python_repl_ast] is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI apologize for the inconvenience. It seems that the python_repl_ast tool is not available. Let me provide the final answer without using the tool.\n",
      "\n",
      "Final Answer: ì˜í¬\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ì˜í¬\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-experimental pandas openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "\n",
    "# 1) ì˜ˆì‹œ ë°ì´í„°í”„ë ˆì„\n",
    "df = pd.DataFrame({\n",
    "    \"ì´ë¦„\": [\"ì² ìˆ˜\", \"ì˜í¬\", \"ë¯¼ìˆ˜\", \"ì§€ì˜\"],\n",
    "    \"ë‚˜ì´\": [23, 25, 21, 29],\n",
    "    \"ì ìˆ˜\": [88, 92, 77, 85]\n",
    "})\n",
    "\n",
    "# 2) LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 3) DataFrame Agent ìƒì„± (âš ï¸ ì½”ë“œ ì‹¤í–‰ ë™ì˜)\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    llm,\n",
    "    df,\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True,       # â† ë°˜ë“œì‹œ ëª…ì‹œ\n",
    "    include_df_in_prompt=True,       # ëª¨ë¸ì— ìƒë‹¨ ní–‰ì„ ë³´ì—¬ì¤„ì§€ ì—¬ë¶€\n",
    "    number_of_head_rows=5,           # ìƒë‹¨ ëª‡ í–‰ì„ ë³´ì—¬ì¤„ì§€\n",
    "    # max_iterations=8,              # í•„ìš” ì‹œ ë°˜ë³µ ì œí•œ\n",
    "    # return_intermediate_steps=True # ì¤‘ê°„ ë‹¨ê³„ ë””ë²„ê¹…ìš©\n",
    ")\n",
    "\n",
    "# 4) ì‹¤í–‰ (.run ë˜ëŠ” .invoke ëª¨ë‘ ê°€ëŠ¥)\n",
    "print(agent.run(\"í‰ê·  ë‚˜ì´ëŠ” ëª‡ ì‚´ì´ì•¼?\"))\n",
    "print(agent.run(\"ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ í•™ìƒì˜ ì´ë¦„ì€ ëˆ„êµ¬ì•¼?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03dd2f-053f-4e99-af70-11921e0e35c6",
   "metadata": {},
   "source": [
    "# âœ… ìµœì¢… ì •ë¦¬\n",
    "- **Agentic RAG**: Retrieverë¥¼ Toolë¡œ ë“±ë¡ â†’ Agentê°€ í•„ìš”ì‹œ ê²€ìƒ‰/í™œìš©\n",
    "- **CSV/Excel ë¶„ì„ Agent**: DataFrameì„ Agentì—ê²Œ ë„˜ê²¨ ìì—°ì–´ ì§ˆì˜ë¡œ ë¶„ì„\n",
    "\n",
    "ğŸ‘‰ Agentë¥¼ í™œìš©í•˜ë©´ ë‹¨ìˆœ QAë¥¼ ë„˜ì–´ **ë™ì  ê²€ìƒ‰Â·ë¶„ì„ ì›Œí¬í”Œë¡œìš°**ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŒ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634acba1-8664-4942-acf4-d573cc1bbc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
