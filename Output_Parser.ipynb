{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71228175-59ce-4a82-a960-91a640674161",
   "metadata": {},
   "source": [
    "# ğŸ“˜ ì¶œë ¥ íŒŒì„œ(Output Parser)\n",
    "\n",
    "---\n",
    "\n",
    "## 01. ì¶œë ¥íŒŒì„œ(Output Parser)\n",
    "\n",
    "### ğŸ“Œ ê°œë…\n",
    "- LLM ì¶œë ¥ì€ ë³´í†µ ììœ  í…ìŠ¤íŠ¸ â†’ ê·¸ëŒ€ë¡œ ì“°ê¸° ì–´ë ¤ì›€\n",
    "- **OutputParser** : LLM ì¶œë ¥ â†’ êµ¬ì¡°í™”ëœ ë°ì´í„°(ë¬¸ìì—´, JSON, ë¦¬ìŠ¤íŠ¸ ë“±) ë³€í™˜\n",
    "- ì¥ì :\n",
    "  - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë¡œì§ê³¼ ì‰½ê²Œ ì—°ê²°\n",
    "  - ì•ˆì •ì ì¸ íŒŒì‹± (ì—ëŸ¬ ì¤„ì„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51398e62-9783-4909-9e83-52b10d481b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-73\n"
     ]
    }
   ],
   "source": [
    "### ğŸ’» ì˜ˆì‹œ ì½”ë“œ\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413f0e83-b398-4446-95f3-34dee2f1cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a decentralized language learning platform that uses blockchain technology to connect language learners with native speakers for personalized lessons.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "print(chain.invoke(\"Answer in one sentence: What is LangChain?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09afbe7c-bcc0-4c55-861a-37d8b5c26ddc",
   "metadata": {},
   "source": [
    "## 02. PydanticOutputParser\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- Pydantic ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ LLM ì¶œë ¥ íŒŒì‹±\n",
    "\n",
    "- ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ìë™ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbbaf3c-dfc3-452c-989c-60565e5efa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='ì² ìˆ˜' age=25\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"ì‚¬ëŒ ì´ë¦„\")\n",
    "    age: int = Field(description=\"ë‚˜ì´\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"ë‹¤ìŒ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•´ì¤˜:\\nì´ë¦„: {name}\\në‚˜ì´: {age}\\n{format_instructions}\",\n",
    "    input_variables=[\"name\", \"age\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "print(chain.invoke({\"name\": \"ì² ìˆ˜\", \"age\": \"25\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4f9c9-fbec-4389-8a65-8f65df11da26",
   "metadata": {},
   "source": [
    "## 03. with_structured_output() ë°”ì¸ë”©\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- LLMì„ ì§ì ‘ Pydantic ëª¨ë¸ì— ë°”ì¸ë”©\n",
    "\n",
    "- ë³„ë„ì˜ íŒŒì„œ ì—°ê²° í•„ìš” ì—†ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad9ddda-8dba-444e-ba87-cd88fb39fab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1927: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='ì˜í¬' age=30\n"
     ]
    }
   ],
   "source": [
    "llm_structured = llm.with_structured_output(Person)\n",
    "print(llm_structured.invoke(\"ì´ë¦„ì€ ì˜í¬ì´ê³  ë‚˜ì´ëŠ” 30ì‚´ì¸ ì‚¬ëŒì˜ JSONì„ ë§Œë“¤ì–´ì¤˜\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cd624-c650-4bc8-abc8-d12d9778bb2a",
   "metadata": {},
   "source": [
    "## 04. LangSmith ì—ì„œ OutputParser íë¦„ í™•ì¸\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì²´ì¸ ì‹¤í–‰ ê³¼ì • ì¶”ì \n",
    "\n",
    "- LLM â†’ OutputParserë¡œ ë³€í™˜ë˜ëŠ” ê³¼ì • ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de76dfc0-c7a2-44c1-bb29-3410248e6e6f",
   "metadata": {},
   "source": [
    "## 05. ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥íŒŒì„œ (CommaSeparatedListOutputParser)\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "\n",
    "- ì˜ˆ: \"ì‚¬ê³¼, ë°°, í¬ë„\" â†’ [\"ì‚¬ê³¼\", \"ë°°\", \"í¬ë„\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d6c4d12-f318-4f30-bb53-fc561f621ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì‚¬ê³¼', 'ë°”ë‚˜ë‚˜', 'ì˜¤ë Œì§€']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"ê³¼ì¼ì„ 3ê°œ ë‚˜ì—´í•´ì¤˜. {format_instructions}\")\n",
    "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
    "\n",
    "print(chain.invoke({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9dc58a-2009-404a-95a2-adb896202e7c",
   "metadata": {},
   "source": [
    "## 06. êµ¬ì¡°í™”ëœ ì¶œë ¥íŒŒì„œ(StructuredOutputParser)\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- JSON Schema ê¸°ë°˜ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "\n",
    "- í‚¤:ê°’ í˜•íƒœ ë°ì´í„° ì¶”ì¶œì— ì í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7503db-437c-4a1d-925b-379e6b20e92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'ì˜í¬', 'hobby': 'ë…ì„œ'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"ì´ë¦„\"),\n",
    "    ResponseSchema(name=\"hobby\", description=\"ì·¨ë¯¸\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"ì‚¬ëŒì˜ ì´ë¦„ê³¼ ì·¨ë¯¸ë¥¼ ì•Œë ¤ì¤˜.\\n{format_instructions}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "print(chain.invoke({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262b138-51ea-41d2-8303-a38677a0df8f",
   "metadata": {},
   "source": [
    "## 07. JSON í˜•ì‹ ì¶œë ¥íŒŒì„œ (JsonOutputParser)\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- LLM ì¶œë ¥ â†’ JSONìœ¼ë¡œ íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fda08a1-df8b-424a-ab58-24ce1ed83375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Great Gatsby', 'author': 'F. Scott Fitzgerald'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"ì±… 1ê¶Œì˜ ì œëª©ê³¼ ì €ìë¥¼ JSONìœ¼ë¡œ ì œê³µí•´ì¤˜.\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
    "print(chain.invoke({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29594e-1b30-45c3-b37d-1b28a94c172c",
   "metadata": {},
   "source": [
    "## 08. Pandas DataFrame ì¶œë ¥íŒŒì„œ (PandasDataFrameOutputParser)\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- LLM ì¶œë ¥ â†’ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "- ë°ì´í„° ë¶„ì„ì— í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab173e63-2acd-4e52-b9b4-9347bef2a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.output_parsers import PandasDataFrameOutputParser\n",
    "\n",
    "# parser = PandasDataFrameOutputParser()\n",
    "\n",
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"3ëª…ì˜ ì´ë¦„ê³¼ ë‚˜ì´ë¥¼ í‘œë¡œ ì‘ì„±í•´ì¤˜.\\n{format_instructions}\"\n",
    "# )\n",
    "\n",
    "# chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
    "# df = chain.invoke({})\n",
    "# print(df)\n",
    "# print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae3c547-e133-49ca-92fe-fcba8a8c2c4e",
   "metadata": {},
   "source": [
    "## 09. ë‚ ì§œí˜•ì‹ ì¶œë ¥íŒŒì„œ (DatetimeOutputParser)\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d3bc7c-e537-406b-a620-1414891542ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-30 15:45:23.123456\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "parser = DatetimeOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"ì˜¤ëŠ˜ ë‚ ì§œë¥¼ {format_instructions}\")\n",
    "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
    "\n",
    "print(chain.invoke({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9757b-6d54-4953-b642-32d910bacade",
   "metadata": {},
   "source": [
    "## 10. ì—´ê±°í˜• ì¶œë ¥íŒŒì„œ (EnumOutputParser)\n",
    "### ğŸ“Œ ê°œë…\n",
    "\n",
    "- LLM ì¶œë ¥ â†’ Enum íƒ€ì…ìœ¼ë¡œ ì œí•œ\n",
    "\n",
    "- íŠ¹ì • ì„ íƒì§€ ì¤‘ í•˜ë‚˜ë§Œ ë°›ë„ë¡ ê°•ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bbd224-faaa-44b3-bf4e-b4ba93df6a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment.positive\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from langchain.output_parsers import EnumOutputParser\n",
    "\n",
    "class Sentiment(Enum):\n",
    "    positive = \"positive\"\n",
    "    negative = \"negative\"\n",
    "    neutral = \"neutral\"\n",
    "\n",
    "parser = EnumOutputParser(enum=Sentiment)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ë¥˜í•´ì¤˜: {sentence}\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
    "print(chain.invoke({\"sentence\": \"ì˜¤ëŠ˜ì€ ê¸°ë¶„ì´ ì¢‹ë‹¤!\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53ead1-3ad7-44d2-bb11-5c7b4bc72409",
   "metadata": {},
   "source": [
    "## âœ… ì •ë¦¬\n",
    "\n",
    "- OutputParser = ììœ  í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™” ë°ì´í„°ë¡œ ë³€í™˜\n",
    "\n",
    "### ì£¼ìš” íŒŒì„œ:\n",
    "\n",
    "- StrOutputParser â†’ ë‹¨ìˆœ ë¬¸ìì—´\n",
    "\n",
    "- PydanticOutputParser â†’ Pydantic ëª¨ë¸ ê¸°ë°˜\n",
    "\n",
    "- CommaSeparatedListOutputParser â†’ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- StructuredOutputParser / JsonOutputParser â†’ JSON\n",
    "\n",
    "- PandasDataFrameOutputParser â†’ DataFrame\n",
    "\n",
    "- DatetimeOutputParser â†’ ë‚ ì§œ\n",
    "\n",
    "- EnumOutputParser â†’ Enum ê°’\n",
    "\n",
    "- LangSmithì—ì„œ íŒŒì‹± íë¦„ ì¶”ì  ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990684f1-25ae-43d4-b23c-f6014c545471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
