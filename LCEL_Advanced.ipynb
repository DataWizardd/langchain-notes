{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e5b658-879b-4a9e-af25-183b77f1b834",
   "metadata": {},
   "source": [
    "### 📌 RunnablePassthrough\n",
    "- 입력을 가공하지 않고 그대로 전달하는 Runnable\n",
    "- 주로 **체인 중간 디버깅/테스트** 용도\n",
    "- 파이프라인 설계할 때 “그대로 흘려보내기” 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6eb901c-aaea-4c01-9b85-a51562d5e758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요!\n"
     ]
    }
   ],
   "source": [
    "#  RunnablePassthrough\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 입력을 그대로 출력\n",
    "passthrough = RunnablePassthrough()\n",
    "print(passthrough.invoke(\"안녕하세요!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261c8f9-ba2b-4629-84da-275dca47df49",
   "metadata": {},
   "source": [
    "### 📌 Runnable 구조확인\n",
    "- LCEL에서 `|` 연산자는 **Runnable** 객체를 연결\n",
    "- 모든 체인은 `RunnableSequence`로 구현됨\n",
    "- `.input_schema` / `.output_schema` → 입력/출력 타입 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f97b34d-679f-4815-a560-8168179e2c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6839a9d-046a-44c2-a566-11253ff77c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.utils.pydantic.PromptInput'>\n",
      "<class 'langchain_openai.chat_models.base.ChatOpenAIOutput'>\n"
     ]
    }
   ],
   "source": [
    "# Runnable 구조확인\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\"너의 이름은 무엇이니?\")\n",
    "\n",
    "chain = prompt | llm\n",
    "print(type(chain))          # RunnableSequence\n",
    "print(chain.input_schema)   # 입력 구조\n",
    "print(chain.output_schema)  # 출력 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f284044-9050-4f28-befc-3b978d723690",
   "metadata": {},
   "source": [
    "### 📌 RunnableLambda\n",
    "- 파이썬 함수를 Runnable로 감싸서 체인에 포함 가능\n",
    "- LLM 호출 없이 **로직 추가**할 때 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436a2943-3bda-4d83-af91-87ea698aacf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# RunnableLambda\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# 간단한 함수 → Runnable로 래핑\n",
    "adder = RunnableLambda(lambda x: x + 10)\n",
    "print(adder.invoke(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e39c6-4858-407c-ab3b-0b416241e723",
   "metadata": {},
   "source": [
    "### 📌 Routing\n",
    "- RunnableBranch를 사용해 **조건에 따라 체인 분기**\n",
    "- 예: 수학 질문 → 계산 LLM, 일반 질문 → 대화 LLM\n",
    "- 복잡한 워크플로우 설계 시 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b26b6dd-d82c-4a45-8d21-a2e8d2da8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='4' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 13, 'total_tokens': 14, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C9vbHxtFCENWwPXUL55zO3Mx0ilKK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--2139ebcb-79b4-40a2-a9e8-ec5bdc5bb499-0' usage_metadata={'input_tokens': 13, 'output_tokens': 1, 'total_tokens': 14, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='저는 항상 같은 기분이에요. 근데 여러분은 어떠신가요? 행복한 하루 되세요!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 17, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C9vbIrnn6cN9YmeihZVCMeKUKAQe1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--02e45f63-46e5-4d2d-83d8-7d9435903b83-0' usage_metadata={'input_tokens': 17, 'output_tokens': 42, 'total_tokens': 59, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 사용자의 질문 의도에 따라 Routing\n",
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "llm_math = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def router(input_text: str):\n",
    "    if any(char.isdigit() for char in input_text):\n",
    "        return \"math\"\n",
    "    return \"chat\"\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: router(x) == \"math\", llm_math),\n",
    "    (lambda x: router(x) == \"chat\", llm_chat),\n",
    "    # default\n",
    "    RunnablePassthrough()\n",
    ")\n",
    "\n",
    "print(branch.invoke(\"2 + 2 = ?\"))\n",
    "print(branch.invoke(\"오늘 기분 어때?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849cab7c-eadd-4520-ae07-f9292c40110a",
   "metadata": {},
   "source": [
    "### 📌 RunnableParallel & itemgetter\n",
    "- **RunnableParallel**: 여러 Runnable을 병렬 실행 → 결과를 dict로 반환\n",
    "- **itemgetter**: 입력 dict에서 특정 key 추출\n",
    "- 병렬 실행으로 **효율성 증가** & 다양한 출력 동시에 생성 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e908aac-1ac0-49f3-8bff-84b17cacc60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first': '오늘 날씨 어때?', 'second': '오늘 날씨 어때?'}\n"
     ]
    }
   ],
   "source": [
    "#  RunnableParallel, itemgetter\n",
    "from operator import itemgetter\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "parallel = RunnableParallel(\n",
    "    first=itemgetter(\"question\"),\n",
    "    second=lambda x: x[\"question\"].upper()\n",
    ")\n",
    "\n",
    "print(parallel.invoke({\"question\": \"오늘 날씨 어때?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c608501-0e0c-4a9d-9eec-fe870ebb851d",
   "metadata": {},
   "source": [
    "### 📌 Config를 활용한 동적 체인 변경\n",
    "- `RunnableConfig`로 실행 시점에 **LLM, Prompt 등 교체 가능**\n",
    "- 하나의 체인으로 다양한 스타일/설정을 실험할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60df828c-46e2-48ea-a7f2-7cb5f01b2bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain은 블록체인 기술을 활용하여 언어 서비스 및 번역 서비스를 제공하는 플랫폼입니다. 이를 통해 언어 관련 서비스의 투명성과 효율성을 높이고, 사용자들 간의 신뢰를 증진시킬 수 있습니다.LangChain은 사용자들이 안전하고 신뢰할 수 있는 언어 서비스를 이용할 수 있도록 도와줍니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 30, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C9vc1RBUAkbAgoW0zJCBkTGtlm3HI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--2d052cef-fb8e-4a06-84ae-6bf3e0b3a6a6-0' usage_metadata={'input_tokens': 30, 'output_tokens': 143, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='LangChain은 언어 및 통역 서비스를 제공하는 블록체인 기술 기반의 플랫폼입니다. 이 플랫폼을 통해 사용자들은 다양한 언어로 통역 서비스를 받을 수 있고, 블록체인 기술을 통해 안전하고 신뢰할 수 있는 서비스를 이용할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 32, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C9vc2SxpFSsk9v6AZHru01VjOGvq5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--49c9c493-ec73-415a-8719-8f305606761f-0' usage_metadata={'input_tokens': 32, 'output_tokens': 119, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 동적으로 LLM 이나 Prompt 를 변경하는 방법(Config)\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"너는 친절한 어시스턴트야. {q}\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"너는 간단명료한 어시스턴트야. {q}\")\n",
    "\n",
    "chain = prompt1 | llm\n",
    "\n",
    "# 기본 실행\n",
    "print(chain.invoke({\"q\": \"LangChain이 뭐야?\"}))\n",
    "\n",
    "# Config로 prompt 변경\n",
    "config = RunnableConfig()\n",
    "dynamic_chain = prompt2 | llm\n",
    "print(dynamic_chain.invoke({\"q\": \"LangChain이 뭐야?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2a9b3-df3d-4745-bc6e-f04ca329a083",
   "metadata": {},
   "source": [
    "### 📌 @chain 데코레이터\n",
    "- 파이썬 함수에 `@chain` 붙이면 Runnable로 변환\n",
    "- `invoke`, `batch`, `stream` 같은 메서드 사용 가능\n",
    "- 장점:\n",
    "  - 직관적인 함수 정의\n",
    "  - 기존 함수 로직을 그대로 체인에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7964e78-3644-45c0-bcc9-f7fe119b437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파이썬 함수에 chain 데코레이터로 runnable 설정\n",
    "# from langchain.chains import chain\n",
    "\n",
    "# @chain\n",
    "# def custom_chain(x: str) -> str:\n",
    "#     return x[::-1]  # 문자열 뒤집기\n",
    "\n",
    "# print(custom_chain.invoke(\"LangChain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dceb22e-fcc6-4b5c-ad2a-a497dd06e076",
   "metadata": {},
   "source": [
    "# ✅ 최종 정리\n",
    "- **RunnablePassthrough** → 입력 그대로 전달  \n",
    "- **Runnable 구조확인** → 체인 input/output schema 확인  \n",
    "- **RunnableLambda** → 함수 기반 runnable  \n",
    "- **Routing (Branch)** → 조건 분기  \n",
    "- **RunnableParallel & itemgetter** → 병렬 실행  \n",
    "- **Config** → 실행 시점에 동적 prompt/LLM 변경  \n",
    "- **@chain 데코레이터** → 파이썬 함수도 runnable 체인으로 확장  \n",
    "\n",
    "👉 LCEL 고급 문법은 RAG, Agent, Workflow 구현 시 **유연한 체인 구성**을 가능하게 해줌\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
